
# Default configuration
default:
  llm:
    list: ${PWD}/models_providers.yaml
    default_model: gpt_4omini_openai # gpt_35_azure # mistral_large_edenai 
    cache : none
    cache_path: ${HOME}/cache_ai/langchain.db
  embeddings:
    list: ${PWD}/models_providers.yaml
    default_model:  multilingual_MiniLM_local #ada_002_edenai #
    cache: ${HOME}/hf_models
  vector_store:
    default: Chroma
    path: ${HOME}/vector_store
    default_collection: "training_session"
  documents:
    base: ./use_case_data
  monitoring: 
    default:  langsmith  # none #
    project: GenAI_demo

  chains:
    path: python.ai_chains
    modules:
      - A_1_joke 
      - B_1_naive_rag_example
      - B_2_self_query
      - C_1_tools_example
      - C_2_advanced_rag_langgraph
      - C_3_essay_writer_agent


# Overridden configurations
# Set by environment variable "BLUEPRINT_CONFIG"
local:
  llm:
    default_model:  llama32_3_ollama
  embeddings:
    default_model: artic_22_ollama

edenai:
  llm:
    default_model: gpt_4omini_edenai
    cache : memory
  embeddings:
    default_model: ada_002_edenai

azure:
  llm:
    default_model: gpt_4_azure
  embeddings:
    default_model: ada_002_azure

