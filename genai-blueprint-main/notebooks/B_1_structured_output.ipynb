{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "!export PYTHONPATH=\":./python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 : provide instruction in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The usual \"tell me a joke\" LLM call.\n",
    "\"\"\"\n",
    "\n",
    "from python.ai_core.llm import get_llm\n",
    "from python.ai_core.prompts import def_prompt\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    the_joke: str = Field(description=\"a good joke\")\n",
    "    explanation: str = Field(description=\"explain why it's funny\")\n",
    "    rate: float = Field(description=\"rate how the joke is funny between 0 and 5\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt_with_format = \"\"\"\n",
    "    tell me  a joke on {topic}     \n",
    "    --- \n",
    "    {format_instructions}\"\"\"\n",
    "\n",
    "structured_prompt = def_prompt(user=prompt_with_format).partial(\n",
    "    format_instructions=parser.get_format_instructions(),\n",
    ")\n",
    "\n",
    "LLM_ID = None\n",
    "structured_joke = structured_prompt | get_llm(llm_id=LLM_ID, json_mode=True) | parser\n",
    "\n",
    "r = structured_joke.invoke({\"topic\": \"cat\"})\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug(structured_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can have a look at the generated prompt:\n",
    "print(structured_prompt.invoke({\"topic\": \"cat\"}).messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method #2 : Use \"with_structured_output\"  (bases on function calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"tell me  a joke on {topic}\"\n",
    "\n",
    "# MODEL = None\n",
    "MODEL = \"gpt_4_azure\"\n",
    "chain = def_prompt(prompt) | get_llm(llm_id=MODEL).with_structured_output(Joke)\n",
    "debug(chain.invoke(({\"topic\": \"cat\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Assignement (Optional)\n",
    "Rate the above joke.\n",
    "Use https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/types/enum/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class JokeRater(Enum):\n",
    "    NOT_SO_GOOD = 0\n",
    "    GOOD = 1\n",
    "    VERY_GOOD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-blueprint-2X6HL8i2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
