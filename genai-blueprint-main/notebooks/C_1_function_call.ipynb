{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function (tools) calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = '/mnt/c/Users/a884470/prj/genai-blueprint-main'  # Change this if needed\n",
    "sys.path.append(os.path.join(project_root, 'python'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from devtools import debug\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "#!export PYTHONPATH=\":./python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from ai_core.llm import get_llm\n",
    "from ai_core.prompts import def_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Ask LLM to return an instantiated function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-14 09:55:39.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mconfig\u001b[0m:\u001b[36myaml_file_config\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mload /mnt/c/Users/a884470/prj/genai-blueprint-main/app_conf.yaml\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-14 09:55:39.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mconfig\u001b[0m:\u001b[36myaml_file_config\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mOverride config from env. variable: azure\u001b[0m\n",
      "\u001b[32m2024-11-14 09:55:39.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mai_core.llm\u001b[0m:\u001b[36mget_llm\u001b[0m:\u001b[36m409\u001b[0m - \u001b[1mget LLM:'gpt_4_azure'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5275/1057213440.py:28 <module>\n",
      "    ai_msg: AIMessage(\n",
      "        content='',\n",
      "        additional_kwargs={\n",
      "            'tool_calls': [\n",
      "                {\n",
      "                    'id': 'call_W5rxC9tNc6Si14S6zQCy40dQ',\n",
      "                    'function': {\n",
      "                        'arguments': '{\"a\":45,\"b\":12}',\n",
      "                        'name': 'add',\n",
      "                    },\n",
      "                    'type': 'function',\n",
      "                },\n",
      "            ],\n",
      "            'refusal': None,\n",
      "        },\n",
      "        response_metadata={\n",
      "            'token_usage': {\n",
      "                'completion_tokens': 17,\n",
      "                'prompt_tokens': 99,\n",
      "                'total_tokens': 116,\n",
      "                'completion_tokens_details': None,\n",
      "                'prompt_tokens_details': None,\n",
      "            },\n",
      "            'model_name': 'gpt-4',\n",
      "            'system_fingerprint': 'fp_5603ee5e2e',\n",
      "            'finish_reason': 'tool_calls',\n",
      "            'logprobs': None,\n",
      "            'content_filter_results': {},\n",
      "        },\n",
      "        id='run-9b87d7d4-f2fc-49ba-8e27-113bde8f35b2-0',\n",
      "        tool_calls=[\n",
      "            {\n",
      "                'name': 'add',\n",
      "                'args': {\n",
      "                    'a': 45,\n",
      "                    'b': 12,\n",
      "                },\n",
      "                'id': 'call_W5rxC9tNc6Si14S6zQCy40dQ',\n",
      "                'type': 'tool_call',\n",
      "            },\n",
      "        ],\n",
      "        usage_metadata={\n",
      "            'input_tokens': 99,\n",
      "            'output_tokens': 17,\n",
      "            'total_tokens': 116,\n",
      "            'input_token_details': {},\n",
      "            'output_token_details': {},\n",
      "        },\n",
      "    ) (AIMessage)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_W5rxC9tNc6Si14S6zQCy40dQ', 'function': {'arguments': '{\"a\":45,\"b\":12}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 99, 'total_tokens': 116, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-9b87d7d4-f2fc-49ba-8e27-113bde8f35b2-0', tool_calls=[{'name': 'add', 'args': {'a': 45, 'b': 12}, 'id': 'call_W5rxC9tNc6Si14S6zQCy40dQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 99, 'output_tokens': 17, 'total_tokens': 116, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm = get_llm(\"mistral_large_edenai\")\n",
    "# llm = get_llm(\"gpt_4omini_edenai\")\n",
    "# llm = get_llm(\"gpt_35_azure\")\n",
    "llm = get_llm(\"gpt_4_azure\")\n",
    "#llm = get_llm(\"llama32_3_ollama\")\n",
    "messages = []\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Addition 2 integer numbers a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    print(\"'add' tool called\")\n",
    "    return a + b\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add]) # tool_choice=\"any\"\n",
    "prompt = def_prompt(\n",
    "    \"Use the provided functions  to compute what is 45 + 12; execute the function. Return 'I don't know' if there are not relevant function  \"\n",
    ")\n",
    "chain = prompt | llm_with_tools\n",
    "ai_msg = chain.invoke({})\n",
    "\n",
    "debug(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5275/3318825891.py:1 <module>\n",
      "    llm_with_tools: RunnableBinding(\n",
      "        bound=AzureChatOpenAI(\n",
      "            name='gpt4-turbo',\n",
      "            client=<openai.resources.chat.completions.Completions object at 0x7f557c553f80>,\n",
      "            async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f557c395b20>,\n",
      "            root_client=<openai.lib.azure.AzureOpenAI object at 0x7f55b47a4740>,\n",
      "            root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7f557c553fb0>,\n",
      "            model_name='gpt4-turbo',\n",
      "            temperature=0.0,\n",
      "            model_kwargs={},\n",
      "            openai_api_key=SecretStr('**********'),\n",
      "            disabled_params={\n",
      "                'parallel_tool_calls': None,\n",
      "            },\n",
      "            azure_endpoint='https://mutualizedopenai.openai.azure.com',\n",
      "            deployment_name='gpt4-turbo',\n",
      "            openai_api_version='2023-05-15',\n",
      "            openai_api_type='azure',\n",
      "        ),\n",
      "        kwargs={\n",
      "            'tools': [\n",
      "                {\n",
      "                    'type': 'function',\n",
      "                    'function': {\n",
      "                        'name': 'add',\n",
      "                        'description': (\n",
      "                            'Addition 2 integer numbers a and b.\\n'\n",
      "                            '\\n'\n",
      "                            '    Args:\\n'\n",
      "                            '        a: first int\\n'\n",
      "                            '        b: second int'\n",
      "                        ),\n",
      "                        'parameters': {\n",
      "                            'properties': {\n",
      "                                'a': {\n",
      "                                    'type': 'integer',\n",
      "                                },\n",
      "                                'b': {\n",
      "                                    'type': 'integer',\n",
      "                                },\n",
      "                            },\n",
      "                            'required': ['a', 'b'],\n",
      "                            'type': 'object',\n",
      "                        },\n",
      "                    },\n",
      "                },\n",
      "            ],\n",
      "        },\n",
      "        config={},\n",
      "        config_factories=[],\n",
      "    ) (RunnableBinding)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=AzureChatOpenAI(name='gpt4-turbo', client=<openai.resources.chat.completions.Completions object at 0x7f557c553f80>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f557c395b20>, root_client=<openai.lib.azure.AzureOpenAI object at 0x7f55b47a4740>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7f557c553fb0>, model_name='gpt4-turbo', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), disabled_params={'parallel_tool_calls': None}, azure_endpoint='https://mutualizedopenai.openai.azure.com', deployment_name='gpt4-turbo', openai_api_version='2023-05-15', openai_api_type='azure'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'add', 'description': 'Addition 2 integer numbers a and b.\\n\\n    Args:\\n        a: first int\\n        b: second int', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug(llm_with_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Execute the function, and send result to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'add' tool called\n",
      "/tmp/ipykernel_5275/3057862763.py:11 <module>\n",
      "    r: AIMessage(\n",
      "        content='The sum of 45 and 12 is 57.',\n",
      "        additional_kwargs={\n",
      "            'refusal': None,\n",
      "        },\n",
      "        response_metadata={\n",
      "            'token_usage': {\n",
      "                'completion_tokens': 13,\n",
      "                'prompt_tokens': 87,\n",
      "                'total_tokens': 100,\n",
      "                'completion_tokens_details': None,\n",
      "                'prompt_tokens_details': None,\n",
      "            },\n",
      "            'model_name': 'gpt-4',\n",
      "            'system_fingerprint': 'fp_5603ee5e2e',\n",
      "            'finish_reason': 'stop',\n",
      "            'logprobs': None,\n",
      "            'content_filter_results': {},\n",
      "        },\n",
      "        id='run-96560d6e-cdc1-41e5-9fbb-55bd9a303523-0',\n",
      "        usage_metadata={\n",
      "            'input_tokens': 87,\n",
      "            'output_tokens': 13,\n",
      "            'total_tokens': 100,\n",
      "            'input_token_details': {},\n",
      "            'output_token_details': {},\n",
      "        },\n",
      "    ) (AIMessage)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The sum of 45 and 12 is 57.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 87, 'total_tokens': 100, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-96560d6e-cdc1-41e5-9fbb-55bd9a303523-0', usage_metadata={'input_tokens': 87, 'output_tokens': 13, 'total_tokens': 100, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "r = llm_with_tools.invoke(messages)\n",
    "\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5275/4208883321.py:1 <module>\n",
      "    messages: [\n",
      "        AIMessage(\n",
      "            content='',\n",
      "            additional_kwargs={\n",
      "                'tool_calls': [\n",
      "                    {\n",
      "                        'id': 'call_W5rxC9tNc6Si14S6zQCy40dQ',\n",
      "                        'function': {\n",
      "                            'arguments': '{\"a\":45,\"b\":12}',\n",
      "                            'name': 'add',\n",
      "                        },\n",
      "                        'type': 'function',\n",
      "                    },\n",
      "                ],\n",
      "                'refusal': None,\n",
      "            },\n",
      "            response_metadata={\n",
      "                'token_usage': {\n",
      "                    'completion_tokens': 17,\n",
      "                    'prompt_tokens': 99,\n",
      "                    'total_tokens': 116,\n",
      "                    'completion_tokens_details': None,\n",
      "                    'prompt_tokens_details': None,\n",
      "                },\n",
      "                'model_name': 'gpt-4',\n",
      "                'system_fingerprint': 'fp_5603ee5e2e',\n",
      "                'finish_reason': 'tool_calls',\n",
      "                'logprobs': None,\n",
      "                'content_filter_results': {},\n",
      "            },\n",
      "            id='run-9b87d7d4-f2fc-49ba-8e27-113bde8f35b2-0',\n",
      "            tool_calls=[\n",
      "                {\n",
      "                    'name': 'add',\n",
      "                    'args': {\n",
      "                        'a': 45,\n",
      "                        'b': 12,\n",
      "                    },\n",
      "                    'id': 'call_W5rxC9tNc6Si14S6zQCy40dQ',\n",
      "                    'type': 'tool_call',\n",
      "                },\n",
      "            ],\n",
      "            usage_metadata={\n",
      "                'input_tokens': 99,\n",
      "                'output_tokens': 17,\n",
      "                'total_tokens': 116,\n",
      "                'input_token_details': {},\n",
      "                'output_token_details': {},\n",
      "            },\n",
      "        ),\n",
      "        ToolMessage(\n",
      "            content='57',\n",
      "            tool_call_id='call_W5rxC9tNc6Si14S6zQCy40dQ',\n",
      "        ),\n",
      "    ] (list) len=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_W5rxC9tNc6Si14S6zQCy40dQ', 'function': {'arguments': '{\"a\":45,\"b\":12}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 99, 'total_tokens': 116, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_5603ee5e2e', 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-9b87d7d4-f2fc-49ba-8e27-113bde8f35b2-0', tool_calls=[{'name': 'add', 'args': {'a': 45, 'b': 12}, 'id': 'call_W5rxC9tNc6Si14S6zQCy40dQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 99, 'output_tokens': 17, 'total_tokens': 116, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " ToolMessage(content='57', tool_call_id='call_W5rxC9tNc6Si14S6zQCy40dQ')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Other method : Use a tool calling agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-14 09:55:56.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mai_core.llm\u001b[0m:\u001b[36mget_llm\u001b[0m:\u001b[36m409\u001b[0m - \u001b[1mget LLM:'gpt_4_azure'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 12, 'b': 1000000}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m1000012\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'x': 100, 'y': 3}`\n",
      "\n",
      "\n",
      "\u001b[0mexponentiate\n",
      "\u001b[33;1m\u001b[1;3m1000000.0\u001b[0m\u001b[32;1m\u001b[1;3mThe result of \\( 12 + 100^3 \\) is 1,000,012.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "/tmp/ipykernel_5275/29369776.py:41 <module>\n",
      "    r: {\n",
      "        'input': 'what is 12  + 100^3',\n",
      "        'output': 'The result of \\\\( 12 + 100^3 \\\\) is 1,000,012.',\n",
      "    } (dict) len=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 12  + 100^3',\n",
       " 'output': 'The result of \\\\( 12 + 100^3 \\\\) is 1,000,012.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = get_llm(\"gpt_4_azure\")\n",
    "#llm = get_llm(\"llama32_3_ollama\")\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Calculate the power of a number. Return x**y (w to the power of y)\"\"\"\n",
    "    print(\"exponentiate\")\n",
    "    return math.pow(x, y)\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful Math Assistant. Please use the provided tool\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tools = [add, exponentiate]\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)  # type: ignore\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)  # type: ignore\n",
    "\n",
    "r = agent_executor.invoke({\"input\": \"what is 12  + 100^3\"})\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call Eden.ai provided tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-blueprint",
   "language": "python",
   "name": "genai-blueprint-ls3xo0xc-py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
