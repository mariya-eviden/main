{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function (tools) calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "!export PYTHONPATH=\":./python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from python.ai_core.llm import get_llm\n",
    "from python.ai_core.prompts import def_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Ask LLM to return an instantiated function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = get_llm(\"mistral_large_edenai\")\n",
    "# llm = get_llm(\"gpt_4omini_edenai\")\n",
    "# llm = get_llm(\"gpt_35_azure\")\n",
    "llm = get_llm(\"gpt_4_azure\")\n",
    "#llm = get_llm(\"llama32_3_ollama\")\n",
    "messages = []\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Addition 2 integer numbers a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    print(\"'add' tool called\")\n",
    "    return a + b\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add]) # tool_choice=\"any\"\n",
    "prompt = def_prompt(\n",
    "    \"Use the provided functions  to compute what is 45 + 12; execute the function. Return 'I don't know' if there are not relevant function  \"\n",
    ")\n",
    "chain = prompt | llm_with_tools\n",
    "ai_msg = chain.invoke({})\n",
    "\n",
    "debug(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug(llm_with_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Execute the function, and send result to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "r = llm_with_tools.invoke(messages)\n",
    "\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Other method : Use a tool calling agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = get_llm(\"gpt_4_azure\")\n",
    "#llm = get_llm(\"llama32_3_ollama\")\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Calculate the power of a number. Return x**y (w to the power of y)\"\"\"\n",
    "    print(\"exponentiate\")\n",
    "    return math.pow(x, y)\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful Math Assistant. Please use the provided tool\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tools = [add, exponentiate]\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)  # type: ignore\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)  # type: ignore\n",
    "\n",
    "r = agent_executor.invoke({\"input\": \"what is 12  + 100^3\"})\n",
    "debug(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call Eden.ai provided tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-blueprint-2X6HL8i2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
