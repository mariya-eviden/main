{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools calling with LangGraph React Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "!export PYTHONPATH=\":./python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devtools import debug\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from python.ai_core.llm import get_llm\n",
    "from python.ai_core.prompts import def_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_community.llms import EdenAI\n",
    "from langchain_community.tools.edenai import (\n",
    "    EdenAiExplicitImageTool,\n",
    "    EdenAiObjectDetectionTool,\n",
    "    EdenAiParsingIDTool,\n",
    "    EdenAiParsingInvoiceTool,\n",
    "    EdenAiSpeechToTextTool,\n",
    "    EdenAiTextModerationTool,\n",
    "    EdenAiTextToSpeechTool,\n",
    ")\n",
    "\n",
    "# llm = EdenAI(\n",
    "#     feature=\"text\", provider=\"openai\", params={\"temperature\": 0.2, \"max_tokens\": 250}\n",
    "# )\n",
    "llm = get_llm(\"gpt_35_azure\")\n",
    "#llm = get_llm(\"gpt_35_openai\")\n",
    "\n",
    "# Define lit of tools\n",
    "\n",
    "tools = [\n",
    "    EdenAiTextModerationTool(providers=[\"openai\"], language=\"en\"),\n",
    "    EdenAiObjectDetectionTool(providers=[\"google\", \"api4ai\"]),\n",
    "    EdenAiTextToSpeechTool(providers=[\"amazon\"], language=\"en\", voice=\"MALE\"),\n",
    "    EdenAiExplicitImageTool(providers=[\"amazon\", \"google\"]),\n",
    "    EdenAiSpeechToTextTool(providers=[\"amazon\"], custom_vocabulary=None, speakers=None),\n",
    "    EdenAiParsingIDTool(providers=[\"amazon\", \"klippa\"], language=\"en\"),\n",
    "    EdenAiParsingInvoiceTool(providers=[\"amazon\", \"google\"], language=\"en\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Select and execute and Eden.AI provided tool with React agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = \"\"\"i have this text : 'i want to slap you' \n",
    "first : i want to know if this text contains explicit content or not .\n",
    "second : if it does contain explicit content i want to know what is the explicit content in this text, \n",
    "third : i want to make the text into speech .\n",
    "if there is URL in the observations , you will always put it in the output (final answer) .\n",
    "\"\"\"\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "response = agent_executor.invoke({\"input\": input_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Same with Tool Calling Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Select and execute and Eden.AI provided tool with React agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Make sure to use the tavily_search_results_json tool for information.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Construct the Tools agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "\n",
    "\n",
    "response = agent_executor.invoke({\"input\": input_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Same with LangGraph React Implementation (actually using tools)\n",
    "\n",
    "Does not work yet with eden api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# langgraph \"create_react_agent\"  is similar to langchain \"create_tool_calling_agent\"AgentExecutor\"AgentExecutor\"AgentExecutor\n",
    "# Don't confuse with legacy lanchain \"create_react_agent\"\n",
    "\n",
    "\n",
    "def is_obscene(input: str) -> bool:\n",
    "    \"check if the input string is obscene or not\"\n",
    "    return False\n",
    "\n",
    "\n",
    "# DOES NOT WORK with Edenai tools...\n",
    "\n",
    "# tools = [is_obscene]  # This work !\n",
    "\n",
    "graph = create_react_agent(llm, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", input_)]}\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-blueprint-2X6HL8i2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
